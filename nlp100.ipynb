{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 文字列の逆順\n",
    "文字列\"stressed\"の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "x = 'stressed'\n",
    "y = x[::-1]\n",
    "print(y)  # desserts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 「パタトクカシーー」\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "x = 'パタトクカシーー'\n",
    "y = x[0::2]\n",
    "print(y)  # パトカー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "x = 'パトカー'\n",
    "y = 'タクシー'\n",
    "z = ''.join(p + q for p, q in zip(x, y))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 円周率\n",
    "\"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 6, 9, 2, 7, 5, 3, 5, 8, 9, 7, 10]\n"
     ]
    }
   ],
   "source": [
    "x = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n",
    "y = [len(word) for word in x.split()]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号\n",
    "\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 0, 'He': 1, 'Li': 2, 'Be': 3, 'B': 4, 'C': 5, 'N': 6, 'O': 7, 'F': 8, 'Ne': 9, 'Na': 10, 'Mi': 11, 'Al': 12, 'Si': 13, 'P': 14, 'S': 15, 'Cl': 16, 'Ar': 17, 'K': 18, 'Ca': 19}\n"
     ]
    }
   ],
   "source": [
    "x = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'\n",
    "x_list = x.split()\n",
    "def cut04(word, index):\n",
    "    index += 1  # 配列の添字と「〜番目」は一つずれるため\n",
    "    if index in [1, 5, 6, 7, 8, 9, 15, 16, 19]:\n",
    "        return word[0]\n",
    "    return word[:2]\n",
    "y = {cut04(word, ind): ind for ind, word in enumerate(x_list)}\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，\"I am an NLPer\"という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_n_gramize(string, n=2):\n",
    "    \"\"\"\n",
    "\n",
    "    :rtype: object\n",
    "    \"\"\"\n",
    "    str_len = len(string)\n",
    "    if str_len < n:\n",
    "        return\n",
    "    tokens = []\n",
    "    for i in range(str_len - n + 1):\n",
    "        tokens.append(string[i:i+n])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_n_gramize(string, n=2):\n",
    "    words = string.split()\n",
    "    word_count = len(words)\n",
    "    if word_count < n:\n",
    "        return\n",
    "    tokens = []\n",
    "    for i in range(word_count -n + 1):\n",
    "        tokens.append(words[i:i+n])\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: [['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "char: ['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "x = 'I am an NLPer'\n",
    "print('word: {}\\nchar: {}'.format(word_n_gramize(x), char_n_gramize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合\n",
    "\"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，'se'というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union: {'ar', 'ap', 'pa', 'di', 'ph', 'is', 'gr', 'ag', 'ra', 'se', 'ad'}\n",
      "intersect: {'ra', 'ar', 'ap', 'pa'}\n",
      "diff: {'is', 'se', 'di', 'ad'}\n",
      "\"se\" is included x: True\n",
      "\"se\" is included y: False\n"
     ]
    }
   ],
   "source": [
    "x = 'paraparaparadise'\n",
    "y = 'paragraph'\n",
    "\n",
    "x_s = set(char_n_gramize(x))\n",
    "y_s = set(char_n_gramize(y))\n",
    "\n",
    "uni = x_s.union(y_s)\n",
    "ints = x_s.intersection(y_s)\n",
    "diff = x_s - y_s\n",
    "print('\\n'.join([\n",
    "    'union: {}'.format(uni),\n",
    "    'intersect: {}'.format(ints),\n",
    "    'diff: {}'.format(diff),\n",
    "    '\"se\" is included x: {}'.format('se' in x_s),\n",
    "    '\"se\" is included y: {}'.format('se' in y_s),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.5\n"
     ]
    }
   ],
   "source": [
    "def tenkiyoho(x, y, z):\n",
    "    template = '{h}時の{k}は{v}'\n",
    "    print(template.format(h=x, k=y, v=z))\n",
    "    \n",
    "\n",
    "tenkiyoho(12, '気温', 22.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 暗号文\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "\n",
    "英小文字ならば(219 - 文字コード)の文字に置換\n",
    "その他の文字はそのまま出力\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cipher(string):\n",
    "    def convert(x):\n",
    "        if x.islower():\n",
    "            return chr(219 - ord(x))\n",
    "        return x\n",
    "    return ''.join(convert(s) for s in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tsviv hslfow yv lmv-- zmw kivuvizyob lmob lmv --lyerlfh dzb gl wl rg.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher('There should be one-- and preferably only one --obvious way to do it.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I cuod'lno bleevie that I cluoo actaullc utdnnerasn what I was redinae : the panneemhoh poweo of the humau mind .\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def typoglycemia(centense):\n",
    "    import random\n",
    "    \n",
    "    def shuf(x):\n",
    "        if len(x) < 5:\n",
    "            return x\n",
    "        y = ''.join(random.sample(x[1:-1], len(x[1:-1])))\n",
    "        return '{}{}{}'.format(x[0], y, x[1])\n",
    "    words = centense.split()\n",
    "    return ' '.join(shuf(w) for w in words)\n",
    "\n",
    "\n",
    "typoglycemia('I couldn\\'t believe that '\n",
    "             'I could actually understand '\n",
    "             'what I was reading : the phenomenal power of the human mind .')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
